# --- Core training & KD stack ---
transformers>=4.40
tokenizers>=0.19
accelerate>=0.29
datasets>=2.18
pyarrow>=14
tqdm>=4.66
jsonschema>=4.21
requests>=2.31
python-dotenv>=1.0

# PyTorch — install a CUDA-matched build separately on Colab/your machine.
# If you really want pip to handle it here (CPU only), uncomment:
# torch>=2.2

# --- Provider SDKs (teacher / APIs) ---
openai>=1.30
anthropic>=0.28
groq>=0.9
google-generativeai>=0.5

# AIMLAPI is OpenAI-compatible; no extra SDK needed if using OPENAI_BASE_URL.

# --- Optional storage backends (install only what you use) ---
# AWS S3
boto3>=1.34
# Dropbox
dropbox>=11.36
# Box
boxsdk[jwt]>=3.9
# Supabase
supabase>=2.6
# Firebase / GCS
google-cloud-storage>=2.17
# WebDAV/Nextcloud can use 'requests' above; specialized client optional:
# webdavclient3>=3.14

# (No package required for OneDrive/iCloud in our code path; they’re URI-only here.)
